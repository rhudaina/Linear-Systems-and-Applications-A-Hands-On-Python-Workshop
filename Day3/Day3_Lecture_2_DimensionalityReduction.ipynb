{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhudaina/Linear-Systems-and-Applications-A-Hands-On-Python-Workshop/blob/main/Day3/Day3_Lecture_2_DimensionalityReduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "5RNGj9vUZwXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gU6miHPmlJaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilinear Regression"
      ],
      "metadata": {
        "id": "h72Iq_M_llsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider a larger data set to determine which factors best predict prices in a housing market."
      ],
      "metadata": {
        "id": "5wE5kgdwlAl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "H = np.loadtxt('housing.data')\n",
        "print(H.shape)\n",
        "\n",
        "H_dataset = pd.DataFrame(H)\n",
        "H_dataset.head()"
      ],
      "metadata": {
        "id": "seSL3AAHIYsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data contains 13 features and prices for 506 houses."
      ],
      "metadata": {
        "id": "vDNTZEu2lVE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = H[:,:-1] # house features (e.g., property tax rate, per-capita crime rate)\n",
        "y = H[:,-1]  # housing values in $1000s"
      ],
      "metadata": {
        "id": "h3hNZKZrlVkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to pad this matrix with an additional column of ones, to take into account the possibility of non-zero constant offset in the regression formula. This corresponds to the \"y-intercept\" in a simple one-dimensional linear regression."
      ],
      "metadata": {
        "id": "4cPHqLhclYsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.pad(A,[(0,0),(0,1)],mode='constant',constant_values=1)"
      ],
      "metadata": {
        "id": "i4SO1pQplZKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform multilinear regression via SVD:"
      ],
      "metadata": {
        "id": "lIDZrMpNldLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import svd\n",
        "U, S, Vh = svd(A, full_matrices=False);\n",
        "\n",
        "D = 1.0/S;\n",
        "x = (Vh.T * D) @ U.T @ y;\n",
        "print(x); # minimum norm solution"
      ],
      "metadata": {
        "id": "GnlyjMuyldjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(y, 'b', label='housing value')\n",
        "plt.plot(A @ x, 'r', label='best-fit price prediction')\n",
        "plt.xlabel('neighborhood')\n",
        "plt.ylabel('median housing value (in $1000s)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8wmOykmDlhjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting data by housing value:"
      ],
      "metadata": {
        "id": "pQDgdw_aloNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sort_ind = np.argsort(y)\n",
        "ys = y[sort_ind] # sorted values\n",
        "As = A[sort_ind,:];\n",
        "\n",
        "plt.plot(ys, 'b', label='housing value')\n",
        "plt.plot(As@x, 'r', label='best-fit price prediction')\n",
        "plt.xlabel('neighborhood')\n",
        "plt.ylabel('median housing value (in $1000s)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tvRQ5MbLlovV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the housing value are not perfectly predicted, the trend agrees quite well. It is often the case that the highest value outliers are not well captured by simple linear fits."
      ],
      "metadata": {
        "id": "tU2srreElsvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principal Component Analysis"
      ],
      "metadata": {
        "id": "-Ut9EJOZltdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SciKit Learn"
      ],
      "metadata": {
        "id": "ToOCCFCE7rJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Scikit-learn](https://scikit-learn.org/stable/) is a library that allows you to do machine learning, that is, make predictions from data, in Python. There are four basic tasks:\n",
        "\n",
        " 1. Regression: predict a number from data points, given data points and corresponding numbers\n",
        " 2. Classification: predict a category from datapoints, given data points and corresponding numbers\n",
        " 3. Clustering: predict a category from data points, given only data points\n",
        " 4. Dimensionality reduction: make data points lower-dimensional so that we can visualize the data\n",
        "\n",
        "Here is a [flowchart from the scikit learn documentation](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) of when to use each technique.\n",
        "\n",
        "![](https://scikit-learn.org/stable/_static/ml_map.png)"
      ],
      "metadata": {
        "id": "D0LG8Hhx7tjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn # scikit-learn"
      ],
      "metadata": {
        "id": "Xo4J8nAS70gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A good place to look for example data sets to use in machine learning tasks is the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)\n",
        "\n",
        "This repository (currently) contains 559 data sets, including information on where they came from and how to use them.\n",
        "\n",
        "On this page we'll use the [Iris](https://archive.ics.uci.edu/ml/datasets/Iris) and [Abalone](https://archive.ics.uci.edu/ml/datasets/Abalone) data sets.\n",
        "\n",
        "The Iris data set consists of measurements of three species of Iris (a flower).  The Abalone data set consists of meaurements of abalone, a type of edible marine snail.\n",
        "\n",
        "You can download the data by going to the data folder for each data set ([here is the one for Iris](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/)).  You will see a file with the extension `*.data` which is a csv file containing the data.  This file does not have a header - you need to look at the attribute information on the data set home page to get the attribute names.\n",
        "\n",
        "Scikit learn also has a few built-in data sets for easy loading:"
      ],
      "metadata": {
        "id": "-6gKHYer77D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "Hj3ZZ1St8AKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "breast = load_breast_cancer()"
      ],
      "metadata": {
        "id": "LyB7NWLMl7GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(breast)"
      ],
      "metadata": {
        "id": "YvK7E6FHl-Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_data = breast.data\n",
        "print(breast_data.shape)"
      ],
      "metadata": {
        "id": "dVR5OI1AmCF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = breast.feature_names\n",
        "print(features.shape)"
      ],
      "metadata": {
        "id": "IRkeV4dBnMp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_labels = breast.target\n",
        "print(breast_labels.shape)"
      ],
      "metadata": {
        "id": "Z9yfhlYwnOnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_dataset = pd.DataFrame(breast_data)\n",
        "breast_dataset.columns = features"
      ],
      "metadata": {
        "id": "LbMR7ixKnQPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_dataset.head()"
      ],
      "metadata": {
        "id": "PvAJVxednR0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA via eigendecomposition"
      ],
      "metadata": {
        "id": "zM7nrDLEnVXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = breast_dataset.loc[:,features].values\n",
        "m,n = A.shape\n",
        "print(A.shape)"
      ],
      "metadata": {
        "id": "Bd8eQ0qVnWwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1. Standardize the data along the features"
      ],
      "metadata": {
        "id": "PUf74RGdnZiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z = (A - A.mean(axis = 0)) / A.std(axis=0)\n",
        "\n",
        "print(\"mean: \", Z.mean())\n",
        "print(\"std: \", Z.std())"
      ],
      "metadata": {
        "id": "x3ik6zbenfCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2. Calculate covariance matrix for the features"
      ],
      "metadata": {
        "id": "GnTjfcbYnmC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = np.cov(Z, ddof = 1, rowvar = False)"
      ],
      "metadata": {
        "id": "tJ_nCMwRnnHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3. Perform eigendecomposition on covariance matrix"
      ],
      "metadata": {
        "id": "GBhTZialnpCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lam, X = np.linalg.eig(C)"
      ],
      "metadata": {
        "id": "CTalWbllnrNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4. Sort (descending) PCs (eigenvectors) based on their eigenvalues"
      ],
      "metadata": {
        "id": "K79HJodbnxiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.argsort(Lam)[::-1] # by default: ascending\n",
        "\n",
        "sorted_eigvals = Lam[idx]\n",
        "sorted_eigvecs = X[:,idx]  # sort columns\n",
        "\n",
        "plt.plot(sorted_eigvals,'-o')\n",
        "plt.ylabel('singular value')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "54Z15SgInzif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5. Calculate the explained variance for each PC"
      ],
      "metadata": {
        "id": "KB7o5tzuoEPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expvar = sorted_eigvals/ np.sum(sorted_eigvals)\n",
        "\n",
        "S = np.cumsum(expvar)\n",
        "plt.plot(S,'-o')\n",
        "plt.ylabel('explained variance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UFO4qfCYoFSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6. Reduce the standardized data by the desired number pf PCs"
      ],
      "metadata": {
        "id": "mdjC7XVqoIVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 5 # desired number of PCs\n",
        "reduced_data = Z @ sorted_eigvecs[:,:p]\n",
        "\n",
        "print(sum(expvar[:p]))"
      ],
      "metadata": {
        "id": "IXvKMzKjoJYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = ['Benign', 'Malignant']\n",
        "colors = ['b', 'r']\n",
        "markers = ['.','x']\n",
        "\n",
        "for i in range(2):\n",
        "  idx = (breast.target == i)\n",
        "  plt.scatter(reduced_data[idx,0], reduced_data[idx,1], marker = markers[i],color = colors[i], label=targets[i])\n",
        "\n",
        "plt.title(\"Principal Component Analysis\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_qD_VmeAoNhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA via SVD"
      ],
      "metadata": {
        "id": "cZnROVCZo9dQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "A = breast_dataset.loc[:,features].values\n",
        "Z = StandardScaler().fit_transform(A)\n",
        "\n",
        "print(Z.mean(), Z.std())"
      ],
      "metadata": {
        "id": "9h8OX1wwo9uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA().fit(Z)\n",
        "S = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "plt.plot(S,'-o')\n",
        "plt.ylabel('explained variance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sxDLgzaOpKmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components = 5)\n",
        "reduced_data = pca.fit_transform(Z)\n",
        "print(Z.shape, reduced_data.shape)\n",
        "\n",
        "targets = ['Benign', 'Malignant']\n",
        "colors = ['b', 'r']\n",
        "markers = ['.','x']\n",
        "\n",
        "for i in range(2):\n",
        "  idx = (breast.target == i)\n",
        "  plt.scatter(reduced_data[idx,0], reduced_data[idx,1], marker = markers[i],color = colors[i], label=targets[i])\n",
        "\n",
        "plt.title(\"Principal Component Analysis\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C3d6u96kpZ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Dimensionality Reducting Routines\n",
        "\n",
        "Note that scikit-learn contains many other unsupervised dimensionality reduction routines: some you might wish to try are\n",
        "Other dimensionality reduction techniques which are useful to know about:\n",
        "\n",
        "- [sklearn.decomposition.PCA](http://scikit-learn.org/0.13/modules/generated/sklearn.decomposition.PCA.html):\n",
        "   Principal Component Analysis\n",
        "- [sklearn.decomposition.RandomizedPCA](http://scikit-learn.org/0.13/modules/generated/sklearn.decomposition.RandomizedPCA.html):\n",
        "   extremely fast approximate PCA implementation based on a randomized algorithm\n",
        "- [sklearn.decomposition.SparsePCA](http://scikit-learn.org/0.13/modules/generated/sklearn.decomposition.SparsePCA.html):\n",
        "   PCA variant including L1 penalty for sparsity\n",
        "- [sklearn.decomposition.FastICA](http://scikit-learn.org/0.13/modules/generated/sklearn.decomposition.FastICA.html):\n",
        "   Independent Component Analysis\n",
        "- [sklearn.decomposition.NMF](http://scikit-learn.org/0.13/modules/generated/sklearn.decomposition.NMF.html):\n",
        "   non-negative matrix factorization\n",
        "- [sklearn.manifold.LocallyLinearEmbedding](http://scikit-learn.org/0.13/modules/generated/sklearn.manifold.LocallyLinearEmbedding.html):\n",
        "   nonlinear manifold learning technique based on local neighborhood geometry\n",
        "- [sklearn.manifold.IsoMap](http://scikit-learn.org/0.13/modules/generated/sklearn.manifold.Isomap.html):\n",
        "   nonlinear manifold learning technique based on a sparse graph algorithm\n",
        "   \n",
        "Each of these has its own strengths & weaknesses, and areas of application. You can read about them on the [scikit-learn website](http://sklearn.org)."
      ],
      "metadata": {
        "id": "Bc7kWrjEq0Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Compression"
      ],
      "metadata": {
        "id": "-odDMiMHp0fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "Img = cv2.imread('sunflowergray.jpg', cv2.IMREAD_GRAYSCALE);\n",
        "print(Img.shape)\n",
        "\n",
        "plt.imshow(Img, cmap = 'gray', vmin = 0, vmax = 255)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AbhIg0U1p1Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import svd\n",
        "U, S, Vh = svd(Img, full_matrices=False)\n",
        "print(U.shape, S.shape, Vh.shape)"
      ],
      "metadata": {
        "id": "6v7Gp-VRp4xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = 5;\n",
        "\n",
        "ApproxImg = (U[:,0:p] * S[0:p]) @ Vh[0:p,:]\n",
        "\n",
        "plt.imshow(ApproxImg, cmap = 'gray', vmin = 0, vmax = 255)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FTYd6jX0qFjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(S,'b')\n",
        "plt.semilogy();\n",
        "\n",
        "p = np.array([5,20,200]);\n",
        "for i in p:\n",
        "  plt.plot(i-1, S[i-1],'r.')"
      ],
      "metadata": {
        "id": "f4893ILpqP7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ImgVar = np.cumsum(S)/np.sum(S);\n",
        "plt.plot(ImgVar, 'b')\n",
        "for i in p:\n",
        "  plt.plot(i-1, ImgVar[i-1],'r.')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BO76HnBeqZmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "1.   [Brad Nelson (2021), Scientific Computing with Python](https://caam37830.github.io/book/index.html)\n",
        "2.   [Krishna et al. (2022) Introduction to Data Science with Python](https://nustat.github.io/DataScience_Intro_python/Introduction%20to%20Python%20and%20Jupyter%20Notebooks.html)\n",
        "3. [Serafina Di Gioia (2024), Python 101, SMR 3935](https://indico.ictp.it/event/10473)\n"
      ],
      "metadata": {
        "id": "Z67jNjHE7fdx"
      }
    }
  ]
}